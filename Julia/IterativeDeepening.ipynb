{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(read(open(\"style.css\"), String))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Deepening"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo: Theory add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "# Pkg.add(\"Chess\")\n",
    "using Chess\n",
    "using Random\n",
    "# Pkg.add(\"DataStructures\")\n",
    "using DataStructures\n",
    "# Pkg.add(\"NBInclude\")\n",
    "using NBInclude\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"EvaluatePosition.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"Memoization.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"QuiescenceSearch.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maxValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `maxValue` function takes in 3 arguments and 2 optional arguments.\n",
    "1. `State` is a chess `state` of type `Board`\n",
    "1. `score` is the static centipawn evaluation of the `state`\n",
    "1. `depth` is the number of halfmoves the engine should analyze before terminating \n",
    "1. `alpha` is optional and is default to -Infinity. Alpha is a minimal value that has been calculated during the recursive process\n",
    "1. `beta`  is optional and is default to Infinity . Beta is a maximal value that has been calculated during the recursive process\n",
    "        \n",
    "The function returns the maximal centipawn evaluation of the current position for the player playing white where both players have played the optimal moves according to the algorithm and terminating after the given depth. All possible moves are sorted by a `PriorityQueue` using the evaluation of the position. Good moves will be prioritized which will increase the chance of pruning paths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function maxValue(State::Board, score::Int64, hash::UInt64, depth::Int64,\n",
    "                  cache::Dict{UInt64, Tuple{String, Int64, Int64}}, alpha::Int64=-200000, beta::Int64=200000)::Int64\n",
    "    if isterminal(State) \n",
    "        return terminal_evaluation(State)\n",
    "    end\n",
    "    if depth == 0\n",
    "        return score\n",
    "        # return quiesceSee(State, score, alpha, beta)\n",
    "        # return quiesce(State, score, hash, alpha, beta)\n",
    "        # return evaluate(State, quiesce, score, hash, 0, alpha, beta)\n",
    "    end\n",
    "    value = alpha\n",
    "    queue = PriorityQueue{Move, Int64}()\n",
    "    for move in moves(State)\n",
    "        undoinfo = domove!(State, move)\n",
    "        val = value_cache(hash, depth-1, cache)\n",
    "        undomove!(State, undoinfo)\n",
    "        if val == nothing\n",
    "            val = -200000\n",
    "        end\n",
    "        enqueue!(queue, move, -val)\n",
    "    end\n",
    "    while !isempty(queue)\n",
    "        move = peek(queue)[1]\n",
    "        nextEval, nextHash = updateBoardData(State, score, hash, move)\n",
    "        undoinfo = domove!(State, move)\n",
    "        value = max(value, evaluate(State, minValue, nextEval, nextHash, depth - 1, cache, value, beta))\n",
    "        undomove!(State, undoinfo)\n",
    "        if value >= beta\n",
    "            return value\n",
    "        end\n",
    "        delete!(queue, move)\n",
    "    end\n",
    "    return value\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `minValue` function takes in 3 arguments and 2 optional arguments.\n",
    "1. `State` is a chess `state` of type `Board`\n",
    "1. `score` is the static centipawn evaluation of the `state`\n",
    "1. `depth` is the number of halfmoves the engine should analyze before terminating \n",
    "1. `alpha` is optional and is default to -Infinity. Alpha is a minimal value that has been calculated during the recursive process\n",
    "1. `beta`  is optional and is default to Infinity . Beta is a maximal value that has been calculated during the recursive process\n",
    "        \n",
    "The function returns the maximal centipawn evaluation of the current position for the player playing white where both players have played the optimal moves according to the algorithm and terminating after the given depth. All possible moves are sorted by a `PriorityQueue` using the evaluation of the position. Good moves will be prioritized which will increase the chance of pruning paths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minValue(State::Board, score::Int64, hash::UInt64, depth::Int64,\n",
    "                  cache::Dict{UInt64, Tuple{String, Int64, Int64}}, alpha::Int64=-200000, beta::Int64=200000)::Int64\n",
    "    if isterminal(State)\n",
    "        return terminal_evaluation(State)\n",
    "    end\n",
    "    if depth == 0\n",
    "        return score\n",
    "        # return quiesceSee(State, score, -beta, -alpha)\n",
    "        # return -quiesce(State, score, hash, -beta, -alpha)\n",
    "        # return -evaluate(State, quiesce, score, hash, 0, -beta, -alpha)\n",
    "    end\n",
    "    value = beta\n",
    "    queue = PriorityQueue{Move, Int64}()\n",
    "    for move in moves(State)\n",
    "        undoinfo = domove!(State, move)\n",
    "        val = value_cache(hash, depth-1, cache)\n",
    "        undomove!(State, undoinfo)\n",
    "        if val == nothing\n",
    "            val = 200000\n",
    "        end\n",
    "        enqueue!(queue, move, val)\n",
    "    end\n",
    "    while !isempty(queue)\n",
    "        move = peek(queue)[1]\n",
    "        nextEval, nextHash = updateBoardData(State, score, hash, move)\n",
    "        undoinfo = domove!(State, move)\n",
    "        value = min(value, evaluate(State, maxValue, nextEval, nextHash, depth - 1, cache, alpha, value))\n",
    "        undomove!(State, undoinfo)\n",
    "        if value <= alpha\n",
    "            return value\n",
    "        end\n",
    "        delete!(queue, move)\n",
    "    end\n",
    "    return value\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `value_cache` is a helping function for the `minValue` and `maxValue` function. It takes in 2 arguments:\n",
    "1. `State` is a chess `state` of type `Board`\n",
    "1. `depth` is the number of halfmoves the engine should analyze before terminating\n",
    "\n",
    "The function looks into the Cache and returns any previously saved values for this position. This information is used to sort good moves inside of the PriorityQueue.\n",
    "The function returns the value for this `state` if the `state` is in the Cache and has a sufficient pre-calculated depth. If the cache does not have an entry for this `state` or entry does not have sufficient depth the function will return `nothing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function value_cache(hash::UInt64, depth::Int64, cache::Dict{UInt64, Tuple{String, Int64, Int64}})\n",
    "    if hash in keys(cache)\n",
    "        _, value, d = cache[hash]\n",
    "        if d >= depth\n",
    "            return value\n",
    "        end\n",
    "    end\n",
    "    # new move or no entry with enough depth\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: pd_evaluate\n",
    "This function performs iterative deepening search on a given state of the board using the evaluation function f and caching the results using the dictionary cache.\n",
    "\n",
    "Arguments:\n",
    "1. `State::Board:` The current state of the board.\n",
    "1. `f::Function:` The evaluation function to use.\n",
    "1. `score::Int64:` The initial score of the board.\n",
    "1. `hash::UInt64:` The hash value of the board.\n",
    "1. `depth::Int64:` The maximum depth to search.\n",
    "1. `cache::Dict{UInt64, Tuple{String, Int64, Int64}}`: The dictionary to cache the results.\n",
    "\n",
    "Returns:\n",
    "1. `bestVal`: The best value found in the search.\n",
    "1. `depth`: The depth at which the best value was found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function pd_evaluate(State::Board, f::Function, score::Int64, hash::UInt64, depth::Int64, \n",
    "                     cache::Dict{UInt64, Tuple{String, Int64, Int64}})\n",
    "    bestVal = score\n",
    "    println(\"Boards score\", score)\n",
    "    for d in 1:depth\n",
    "        bestVal = evaluate(State, f, score, hash, d, cache)\n",
    "        println(\"Best score: \", bestVal)\n",
    "        if abs(bestVal) == 100000\n",
    "            return bestVal, d\n",
    "        end\n",
    "    end\n",
    "    return bestVal, depth\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: iterativeDeepening\n",
    "This function performs iterative deepening search on the given State and returns the best move found.\n",
    "\n",
    "Arguments:\n",
    "1. `State::Board:` A chess board in the current state.\n",
    "1. `score::Int64:` The current score of the board.\n",
    "1. `hash::UInt64:` The current hash value of the board.\n",
    "1. `depth::Int64:` The maximum depth to search.\n",
    "1. `cache::Dict{UInt64, Tuple{String, Int64, Int64}}`: TThe cache dictionary to store the evaluated board states. It is optional and initialized by initCache() function by default.\n",
    "\n",
    "Returns:\n",
    "1. `bestVal`: The best score found by the iterative deepening search.\n",
    "1. `BestMove`: The best move found by the iterative deepening search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function iterativeDeepening(State::Board, score::Int64, hash::UInt64, depth::Int64, \n",
    "                            cache::Dict{UInt64, Tuple{String, Int64, Int64}} = initCache())\n",
    "    side = sidetomove(State)\n",
    "    bestVal, depth = (side == WHITE) ? pd_evaluate(State, maxValue, score, hash, depth, cache) : \n",
    "                                       pd_evaluate(State, minValue, score, hash, depth, cache)\n",
    "    next_moves = moves(State)\n",
    "\n",
    "    BestMoves::Array{Move} = [move for move in next_moves if zobrist_hash(State, hash, move) in keys(cache) &&\n",
    "                                                cache[zobrist_hash(State, hash, move)][1] == \"=\" &&\n",
    "                                                cache[zobrist_hash(State, hash, move)][2] == bestVal]\n",
    "    \n",
    "    BestMove::Move = rand(BestMoves)\n",
    "    return bestVal, BestMove\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
