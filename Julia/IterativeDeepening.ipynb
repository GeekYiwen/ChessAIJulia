{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(read(open(\"style.css\"), String))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Deepening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "# Pkg.add(\"Chess\")\n",
    "using Chess\n",
    "using Random\n",
    "# Pkg.add(\"DataStructures\")\n",
    "using DataStructures\n",
    "# Pkg.add(\"NBInclude\")\n",
    "using NBInclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"EvaluatePosition.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"Memoization.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"QuiescenceSearch.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maxValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `maxValue` function takes in 3 arguments and 2 optional arguments.\n",
    "1. `State` is a chess `state` of type `Board`\n",
    "1. `score` is the static centipawn evaluation of the `state`\n",
    "1. `depth` is the number of halfmoves the engine should analyze before terminating \n",
    "1. `alpha` is optional and is default to -Infinity. Alpha is a minimal value that has been calculated during the recursive process\n",
    "1. `beta`  is optional and is default to Infinity . Beta is a maximal value that has been calculated during the recursive process\n",
    "        \n",
    "The function returns the maximal centipawn evaluation of the current position for the player playing white where both players have played the optimal moves according to the algorithm and terminating after the given depth. All possible moves are sorted by a `PriorityQueue` using the evaluation of the position. Good moves will be prioritized which will increase the chance of pruning paths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function maxValue(State::Board, score::Int64, hash::UInt64, depth::Int64,\n",
    "                  cache::Dict{UInt64, Tuple{String, Int64, Int64}}, alpha::Int64=-200000, beta::Int64=200000)::Int64\n",
    "    if isterminal(State) \n",
    "        return terminal_evaluation(State)\n",
    "    end\n",
    "    if depth == 0\n",
    "        return score\n",
    "        # return quiesceSee(State, score, alpha, beta)\n",
    "        # return quiesce(State, score, hash, alpha, beta)\n",
    "        # return evaluate(State, quiesce, score, hash, 0, alpha, beta)\n",
    "    end\n",
    "    value = alpha\n",
    "    queue = PriorityQueue{Move, Int64}()\n",
    "    for move in moves(State)\n",
    "        undoinfo = domove!(State, move)\n",
    "        val = value_cache(hash, depth-1, cache)\n",
    "        undomove!(State, undoinfo)\n",
    "        if val == nothing\n",
    "            val = -200000\n",
    "        end\n",
    "        enqueue!(queue, move, -val)\n",
    "    end\n",
    "    while !isempty(queue)\n",
    "        move = peek(queue)[1]\n",
    "        nextEval, nextHash = updateBoardData(State, score, hash, move)\n",
    "        undoinfo = domove!(State, move)\n",
    "        value = max(value, evaluate(State, minValue, nextEval, nextHash, depth - 1, cache, value, beta))\n",
    "        undomove!(State, undoinfo)\n",
    "        if value >= beta\n",
    "            return value\n",
    "        end\n",
    "        delete!(queue, move)\n",
    "    end\n",
    "    return value\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `minValue` function takes in 3 arguments and 2 optional arguments.\n",
    "1. `State` is a chess `state` of type `Board`\n",
    "1. `score` is the static centipawn evaluation of the `state`\n",
    "1. `depth` is the number of halfmoves the engine should analyze before terminating \n",
    "1. `alpha` is optional and is default to -Infinity. Alpha is a minimal value that has been calculated during the recursive process\n",
    "1. `beta`  is optional and is default to Infinity . Beta is a maximal value that has been calculated during the recursive process\n",
    "        \n",
    "The function returns the maximal centipawn evaluation of the current position for the player playing white where both players have played the optimal moves according to the algorithm and terminating after the given depth. All possible moves are sorted by a `PriorityQueue` using the evaluation of the position. Good moves will be prioritized which will increase the chance of pruning paths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minValue(State::Board, score::Int64, hash::UInt64, depth::Int64,\n",
    "                  cache::Dict{UInt64, Tuple{String, Int64, Int64}}, alpha::Int64=-200000, beta::Int64=200000)::Int64\n",
    "    if isterminal(State)\n",
    "        return terminal_evaluation(State)\n",
    "    end\n",
    "    if depth == 0\n",
    "        return score\n",
    "        # return quiesceSee(State, score, -beta, -alpha)\n",
    "        # return -quiesce(State, score, hash, -beta, -alpha)\n",
    "        # return -evaluate(State, quiesce, score, hash, 0, -beta, -alpha)\n",
    "    end\n",
    "    value = beta\n",
    "    queue = PriorityQueue{Move, Int64}()\n",
    "    for move in moves(State)\n",
    "        undoinfo = domove!(State, move)\n",
    "        val = value_cache(hash, depth-1, cache)\n",
    "        undomove!(State, undoinfo)\n",
    "        if val == nothing\n",
    "            val = 200000\n",
    "        end\n",
    "        enqueue!(queue, move, val)\n",
    "    end\n",
    "    while !isempty(queue)\n",
    "        move = peek(queue)[1]\n",
    "        nextEval, nextHash = updateBoardData(State, score, hash, move)\n",
    "        undoinfo = domove!(State, move)\n",
    "        value = min(value, evaluate(State, maxValue, nextEval, nextHash, depth - 1, cache, alpha, value))\n",
    "        undomove!(State, undoinfo)\n",
    "        if value <= alpha\n",
    "            return value\n",
    "        end\n",
    "        delete!(queue, move)\n",
    "    end\n",
    "    return value\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `value_cache` is a helping function for the `minValue` and `maxValue` function. It takes in 2 arguments:\n",
    "1. `State` is a chess `state` of type `Board`\n",
    "1. `depth` is the number of halfmoves the engine should analyze before terminating\n",
    "\n",
    "The function looks into the Cache and returns any previously saved values for this position. This information is used to sort good moves inside of the PriorityQueue.\n",
    "The function returns the value for this `state` if the `state` is in the Cache and has a sufficient pre-calculated depth. If the cache does not have an entry for this `state` or entry does not have sufficient depth the function will return `nothing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function value_cache(hash::UInt64, depth::Int64, cache::Dict{UInt64, Tuple{String, Int64, Int64}})\n",
    "    if hash in keys(cache)\n",
    "        _, value, d = cache[hash]\n",
    "        if d >= depth\n",
    "            return value\n",
    "        end\n",
    "    end\n",
    "    # new move or no entry with enough depth\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `alphaBetaPruning` function takes in 3 arguments\n",
    "1. `State` is the current state of type `Board`\n",
    "1. `score` is the static centipawn evaluation of the static position\n",
    "1. `depth` is the number of halfmoves the engine should analyze before terminating\n",
    "\n",
    "The function returns the best value and the best move the moving player can play in the current position. It calls the `Iterative Deepening` algorithm. If multiple moves are found which result in the best evaluation a random move will be chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function pd_evaluate(State::Board, f::Function, score::Int64, hash::UInt64, depth::Int64, \n",
    "                     cache::Dict{UInt64, Tuple{String, Int64, Int64}})\n",
    "    bestVal = score\n",
    "    for d in 1:depth\n",
    "        bestVal = evaluate(State, f, score, hash, d, cache)\n",
    "        if bestVal in [-100000, 100000]\n",
    "            return bestVal, d\n",
    "        end\n",
    "    end\n",
    "    return bestVal, depth\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function iterativeDeepening(State::Board, score::Int64, hash::UInt64, depth::Int64, \n",
    "                            cache::Dict{UInt64, Tuple{String, Int64, Int64}} = initCache())\n",
    "    side = sidetomove(State)\n",
    "    bestVal, depth = (side == WHITE) ? pd_evaluate(State, maxValue, score, hash, depth, cache) : \n",
    "                                       pd_evaluate(State, minValue, score, hash, depth, cache)\n",
    "    next_moves = moves(State)\n",
    "    BestMoves::Array{Move} = []\n",
    "    for move in next_moves\n",
    "        nextHash=zobrist_hash(State,hash,move )\n",
    "        \n",
    "        if !(nextHash in keys(cache))\n",
    "            continue\n",
    "        end\n",
    "        flag, val, d = cache[nextHash]\n",
    "        if flag ==\"=\" && val==bestVal \n",
    "            append!(BestMoves, [move])\n",
    "        end    \n",
    "    end\n",
    "    \n",
    "    BestMove::Move = rand(BestMoves)\n",
    "    return bestVal, BestMove\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
