{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(read(open(\"style.css\"), String))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Deepening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements the iterative deepening algorithm.\n",
    "\n",
    "Add move ordering to the alpha-beta-pruning algorithm to improve the performance of the search. It works by repeatedly applying alpha-beta pruning to a game tree with increasing depth limits until a certain time limit is reached or a mate is found. The iterative deepening algorithm iterates over the depth starting at a depth of 1. It will search the game tree to a depth of 1. Using the evaluation it can then order the next moves after their evaluation. Moves with a good evaluation have a high chance of being actual good moves, resulting in more paths pruned when searching the game tree. It will run until it has reached the maximum depth. When it finds a forced mate at any stage, this is also the shortest way of mating the opponent. \n",
    "Improve alpha-beta Pruning is to use move ordering heuristics, which involve evaluating and ordering moves based on their likelihood of leading to a good outcome.\n",
    "This approach allows the algorithm to focus on the most promising branches of the game tree while still exploring deeper levels when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "# Pkg.add(\"Chess\")\n",
    "using Chess\n",
    "using Random\n",
    "# Pkg.add(\"DataStructures\")\n",
    "using DataStructures\n",
    "# Pkg.add(\"NBInclude\")\n",
    "using NBInclude\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"AdvancedBoard.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"Memoization.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"QuiescenceSearch.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maxValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `maxValue` returns the minimal centipawn evaluation of the current position for the player playing white where both players have played the optimal moves according to the algorithm and terminating after the given depth. All possible moves are sorted by a `PriorityQueue` using the evaluation of the position. Good moves will be prioritized which will increase the chance of pruning paths. \n",
    "\n",
    "Arguments:\n",
    "\n",
    "1. `aBoard::AdvBoard` is a chess `state`\n",
    "1. `depth::Int64` is the number of halfmoves the engine should analyze before terminating \n",
    "1. `alpha::Int64` is a minimal value that has been calculated during the recursive process\n",
    "1. `beta::Int64`  is a maximal value that has been calculated during the recursive process\n",
    "1. `flagQuiesce::Bool` is an optional flag specifies whether the quiesce-search should be used. If not then the `see`-variant of the quiesce-search will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function maxValue(aBoard::AdvBoard, depth::Int64,\n",
    "                  cache::Dict{UInt64, Tuple{String, Int64, Int64}}, alpha::Int64, beta::Int64, flagQuiesce::Bool=false)::Int64\n",
    "    if isterminal(aBoard.state) \n",
    "        return terminal_evaluation(aBoard)\n",
    "    end\n",
    "    if depth == 0\n",
    "        # return aBoard.score\n",
    "        if flagQuiesce\n",
    "            return quiesceMax(aBoard, 0, alpha, beta)\n",
    "            # return evaluate(aBoard, quiesceMax, 0, cache, alpha, beta)\n",
    "        else\n",
    "            return aBoard.score\n",
    "        end\n",
    "    end\n",
    "    value = alpha\n",
    "    queue = PriorityQueue{Move, Int64}()\n",
    "    for move in moves(aBoard.state)\n",
    "        nextHash = zobrist_hash(aBoard.state, aBoard.hash, move)\n",
    "        val = value_cache(nextHash, depth-2, cache)\n",
    "        if val == nothing\n",
    "            val = -200000\n",
    "        end\n",
    "        enqueue!(queue, move, -val)\n",
    "    end\n",
    "    while !isempty(queue)\n",
    "        move = peek(queue)[1]\n",
    "        undo = domoveAdv!(aBoard, move)\n",
    "        value = max(value, evaluate(aBoard, minValue,  depth - 1, cache, value, beta, flagQuiesce))\n",
    "        undomoveAdv!(aBoard, undo)\n",
    "        if value >= beta\n",
    "            return value\n",
    "        end\n",
    "        delete!(queue, move)\n",
    "    end\n",
    "    return value\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `minValue` returns the maximal centipawn evaluation of the current position for the player playing black where both players have played the optimal moves according to the algorithm and terminating after the given depth. All possible moves are sorted by a `PriorityQueue` using the evaluation of the position. Good moves will be prioritized which will increase the chance of pruning paths. \n",
    "\n",
    "Arguments:\n",
    "\n",
    "1. `aBoard::AdvBoard` is a chess `state`\n",
    "1. `depth::Int64`     is the number of halfmoves the engine should analyze before terminating \n",
    "1. `alpha::Int64`     is a minimal value that has been calculated during the recursive process\n",
    "1. `beta::Int64`      is a maximal value that has been calculated during the recursive process\n",
    "1. `flagQuiesce::Bool`is an optional flag specifies whether the quiesce-search should be used. If not then the `see`-variant of the quiesce-search will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minValue(aBoard::AdvBoard, depth::Int64,\n",
    "                  cache::Dict{UInt64, Tuple{String, Int64, Int64}}, alpha::Int64, beta::Int64, flagQuiesce::Bool=false)::Int64\n",
    "    if isterminal(aBoard.state)\n",
    "        return terminal_evaluation(aBoard)\n",
    "    end\n",
    "    if depth == 0\n",
    "        # return aBoard.score\n",
    "        if flagQuiesce\n",
    "            return quiesceMin(aBoard,  0,  alpha, beta) \n",
    "            # return evaluate(aBoard,quiesceMin , 0, cache, alpha, beta) with Transposition\n",
    "        else\n",
    "            return aBoard.score\n",
    "        end\n",
    "    end\n",
    "    value = beta\n",
    "    queue = PriorityQueue{Move, Int64}()\n",
    "    for move in moves(aBoard.state)\n",
    "        nextHash = zobrist_hash(aBoard.state, aBoard.hash, move)\n",
    "        val = value_cache(nextHash, depth-2, cache)\n",
    "        if val == nothing\n",
    "            val = 200000\n",
    "        end\n",
    "        enqueue!(queue, move, val)\n",
    "    end\n",
    "    while !isempty(queue)\n",
    "        move = peek(queue)[1]\n",
    "        Undo = domoveAdv!(aBoard, move)\n",
    "        value = min(value, evaluate(aBoard, maxValue, depth - 1, cache, alpha, value, flagQuiesce))\n",
    "        undomoveAdv!(aBoard, Undo)\n",
    "        if value <= alpha\n",
    "            return value\n",
    "        end\n",
    "        delete!(queue, move)\n",
    "    end\n",
    "    return value\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `value_cache` is a helping function for the `minValue` and `maxValue` function. It takes in 2 arguments:\n",
    "\n",
    "1. `hash::UInt64` is a chess `state` of type `Board`\n",
    "1. `depth::Int64` is the number of halfmoves the engine should analyze before terminating\n",
    "1. `cache::Dict{UInt64, Tuple{String, Int64, Int64}}` is the cache that is searched\n",
    "\n",
    "The function looks into the cache and returns any previously saved values for this position. This information is used to sort good moves inside of the PriorityQueue.\n",
    "The function returns the value for this `hash` if the `hash` is in the Cache and has a sufficient pre-calculated depth. If the cache does not have an entry for this `hash` or entry does not have sufficient depth the function will return `nothing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function value_cache(hash::UInt64, depth::Int64, cache::Dict{UInt64, Tuple{String, Int64, Int64}})\n",
    "    tuple::Tuple{String, Int64, Int64} = get(cache, hash, (\"\", 0, 0))\n",
    "    if tuple != (\"\", 0, 0)\n",
    "        _, value, d = tuple\n",
    "        if d >= depth\n",
    "            return value\n",
    "        end\n",
    "    end\n",
    "    # new move or no entry with enough depth\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: pd_evaluate\n",
    "This function performs iterative deepening search on a given state of the board using the evaluation function f and caching the results using the dictionary cache.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "1. `aBoard::AdvBoard` is a chess board in the current state\n",
    "1. `f::Function` is the evaluation function that will be called\n",
    "1. `depth::Int64` is the maximum depth of the search\n",
    "1. `cache::Dict{UInt64, Tuple{String, Int64, Int64}}` is the dictionary to cache the results\n",
    "1. `quiece:: Boolean` is Flag to use QuienceSearch\n",
    "1. `increaseDepth:: Float` an number indicating the time threshold in seconds. If the search time is lower than this value and the current depth equals depth, the depth is increased by one. To deactivate this feature, you have to set this parameter to zero.\n",
    "1. `showTimes:: Boolean` is Flag to print Time and SearchDepth\n",
    "\n",
    "Returns:\n",
    "\n",
    "1. `bestVal`: The best value found in the search.\n",
    "1. `depth`: The depth at which the best value was found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function pd_evaluate(aBoard::AdvBoard, f::Function, depth::Int64, \n",
    "                     cache::Dict{UInt64, Tuple{String, Int64, Int64}}, quiece, increaseDepth, showTimes)\n",
    "    bestVal = aBoard.score\n",
    "    # println(\"Boards score \", score)\n",
    "    d = 1\n",
    "    alpha = -100000\n",
    "    beta = 100000\n",
    "    while d <= depth\n",
    "        # start time\n",
    "        starttime = time()\n",
    "        flagQuiesce = quiece && (d == depth)\n",
    "        bestVal = evaluate(aBoard, f, d, cache, alpha, beta, flagQuiesce)\n",
    "        if abs(bestVal) == 100000\n",
    "            return bestVal, d\n",
    "        end\n",
    "        # Check if is d equals depth and the difference between startime and currenttime increases depth\n",
    "        if showTimes\n",
    "            println(\"The best value was calculated with a depth of $d and it took $(time() - starttime ) seconds. \")\n",
    "        end\n",
    "        if increaseDepth != 0 && d == depth && time() - starttime < increaseDepth\n",
    "            depth += 1 \n",
    "        end\n",
    "        d +=1\n",
    "    end\n",
    "    return bestVal, depth\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: iterativeDeepening\n",
    "This function performs iterative deepening search on the given State and returns the best move found.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "1. `aBoard::AdvBoard` is a chess board in the current state\n",
    "1. `depth::Int64` is the maximum depth to search\n",
    "1. `cache::Dict{UInt64, Tuple{String, Int64, Int64}}` is the cache dictionary to store the evaluated board states. It is optional and initializes an empty Dictionary by default.\n",
    "1. `quiece:: Boolean` is Flag to use QuienceSearch. It is optional and initializes to true by default.\n",
    "1. `timeBoundIncreaseDepth:: Float` a time threshold to increase depth. \n",
    "1. `showTimes:: Boolean` is Flag to print Time and SearchDepth. It is optional and initializes to true by default.\n",
    "\n",
    "Returns:\n",
    "\n",
    "1. `bestVal`: The best score found by the iterative deepening search.\n",
    "1. `BestMove`: The best move found by the iterative deepening search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function iterativeDeepening(aBoard::AdvBoard,  depth::Int64, \n",
    "                            cache::Dict{UInt64, Tuple{String, Int64, Int64}} = initCache(), \n",
    "                            quiese::Bool = true, timeBoundIncreaseDepth::Float64 = 1.0, showTime::Bool = true)\n",
    "    side = sidetomove(aBoard.state)\n",
    "    bestVal, depth = (side == WHITE) ? pd_evaluate(aBoard, maxValue, depth, cache, quiese, timeBoundIncreaseDepth, showTime) : \n",
    "                                       pd_evaluate(aBoard, minValue, depth, cache, quiese, timeBoundIncreaseDepth, showTime)\n",
    "    next_moves = moves(aBoard.state)\n",
    "    \n",
    "    # BestMoves::Array{Move} = []\n",
    "\n",
    "    # queue = PriorityQueue{Move, Int64}()\n",
    "    # for move in next_moves\n",
    "    #     nextHash = zobrist_hash(aBoard.state, aBoard.hash, move)\n",
    "    #     val = value_cache(nextHash, depth-2, cache)\n",
    "    #     if val == nothing\n",
    "    #         val = 200000\n",
    "    #     else\n",
    "    #         if side == WHITE\n",
    "    #             val = -1 * val\n",
    "    #         end\n",
    "    #     end\n",
    "    #     enqueue!(queue, move, val)\n",
    "    # end\n",
    "    \n",
    "    # while !isempty(queue)\n",
    "    #     move = peek(queue)[1]\n",
    "    #     undoinfo = domoveAdv!(aBoard, move)\n",
    "    #     if side == WHITE\n",
    "    #         if evaluate(aBoard, minValue, depth-1, cache, -100000, 100000, quiese) == bestVal\n",
    "    #             append!(BestMoves, [move])\n",
    "    #             undomoveAdv!(aBoard, undoinfo)\n",
    "    #             break\n",
    "    #         end\n",
    "    #     else \n",
    "    #         if evaluate(aBoard, maxValue, depth-1, cache, -100000, 100000, quiese) == bestVal\n",
    "    #             append!(BestMoves, [move])\n",
    "    #             undomoveAdv!(aBoard, undoinfo)\n",
    "    #             break\n",
    "    #         end\n",
    "    #     end\n",
    "    #     undomoveAdv!(aBoard, undoinfo)\n",
    "    #     delete!(queue, move)\n",
    "    # end\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # Variation? Klappt nur, wenn einer der besten Pfade mit \"=\" flag im Cache schon gespeichert ist. \n",
    "    # Wirft Fehler, wenn man Ruhesuche verwendet\n",
    "    println(bestVal)\n",
    "    BestMoves::Array{Move} = [move for move in next_moves if zobrist_hash(aBoard.state, aBoard.hash, move) in keys(cache) &&\n",
    "                                                          cache[zobrist_hash(aBoard.state, aBoard.hash, move)][1] == \"=\" &&\n",
    "                                                          cache[zobrist_hash(aBoard.state, aBoard.hash, move)][2] == bestVal]\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    if length(BestMoves) == 0\n",
    "        for move in next_moves\n",
    "            undoinfo = domoveAdv!(aBoard, move)\n",
    "            if side == WHITE\n",
    "                if evaluate(aBoard, minValue, depth-1, cache, -100000, 100000, quiese) == bestVal\n",
    "                    append!(BestMoves, [move])\n",
    "                end\n",
    "            else \n",
    "                if evaluate(aBoard, maxValue, depth-1, cache, -100000, 100000, quiese) == bestVal\n",
    "                    append!(BestMoves, [move])\n",
    "                end\n",
    "            end\n",
    "            undomoveAdv!(aBoard, undoinfo)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # # Debug\n",
    "    # for move in next_moves\n",
    "    #   nextHash = zobrist_hash(aBoard.state, aBoard.hash, move)\n",
    "    #   if nextHash in keys(cache)\n",
    "    #       println(cache[nextHash])\n",
    "    #   else\n",
    "    #       println(\"Move \", move, \" not in cache.\")\n",
    "    #   end\n",
    "    # end\n",
    "    BestMove::Move = rand(BestMoves)\n",
    "    \n",
    "    return bestVal, BestMove\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.4",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
