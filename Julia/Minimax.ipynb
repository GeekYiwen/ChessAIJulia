{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(read(open(\"style.css\"), String))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimax\n",
    "A program to play a game of chess using the Minimax algorithm. The Minimax algorithm calculates all different possibilities of the current position and chooses the best move. It assumes that all players try to play the best possible moves. From whites perspective white chooses the best move of blacks best moves. We have to limit the amout of moves that minimax will go into the future due to the huge amount of possibilities that chess has. Therefore we stop the minimax algorithm at a certain depth.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "# Pkg.add(\"Chess\")\n",
    "using Chess\n",
    "using Random\n",
    "\n",
    "# Pkg.add(\"NBInclude\")\n",
    "using NBInclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"EvaluatePosition.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Global Cache initiallized in Main notebook `Play.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxValue-function\n",
    "This function looks for the maximum value that white can achieve from a position. Meanwhile black tries to minimize the value of the position. Therefore white will take the maximal value of the minimum value of the next move that can happen.\n",
    "\n",
    "Note: The depth is subtracted to give a better/worse rating to evaluate short mating paths as a petter path. (if there is a Mate in 3 (M3) and M1 Path then choose the M1 Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`maxValue(State::Board, depth::Int64)` is the **non-incremental** implementation of the maxValue function. It takes in the current `State` (Type `Board`) and the max-`depth` (Type `Int64`) it should calculate and returns the maximal score it can achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function maxValue(State::Board, depth::Int64)::Int64\n",
    "    if isterminal(State) || depth == 0\n",
    "        return evaluate_position(State) - depth\n",
    "    end\n",
    "    return maximum([ minValue(domove(State, ns), depth-1) for ns in moves(State) ])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`maxValue(State::Board, score, depth::Int64)` is the **incremental** implementation of the maxValue function. It takes in the current `State` (Type `Board`), the current centipawn-`score` of the board and the max-`depth` (Type `Int64`) it should calculate and returns the maximal score it can achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function maxValue(State::Board, score::Int64, depth::Int64)::Int64\n",
    "    if isterminal(State) \n",
    "        return terminal_evaluation(State) - depth\n",
    "    end\n",
    "    if depth == 0\n",
    "        return score\n",
    "    end\n",
    "    value = -Inf\n",
    "    for move in moves(State)\n",
    "        nextEval = evaluate_move(State, move, score)\n",
    "        undoinfo = domove!(State, move)\n",
    "        value = max(minValue(State, nextEval, depth-1), value)\n",
    "        undomove!(State, undoinfo)\n",
    "    end\n",
    "    return value\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with Memoization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is the same maxValue function above. Additionally it will save the calculated score in a global Cache. It will retrieve the value if it has already been calculated. It therefore must already be in the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function maxValue(State::Board, score::Int64, depth::Int64, cache)::Int64\n",
    "    # Memoization\n",
    "    entry = (\"maxValue\", deepcopy(State), depth)\n",
    "    if entry in keys(cache)\n",
    "        return cache[entry]\n",
    "    end\n",
    "    if isterminal(State)\n",
    "        result = terminal_evaluation(State) - depth\n",
    "    elseif depth == 0\n",
    "        result = score\n",
    "    else\n",
    "        result = -Inf\n",
    "        for move in moves(State)\n",
    "            nextEval = evaluate_move(State, move, score)\n",
    "            undoinfo = domove!(State, move)\n",
    "            result = max(minValue(State, nextEval, depth-1, cache), result)\n",
    "            undomove!(State, undoinfo)\n",
    "        end\n",
    "    end\n",
    "    # Save in Cache\n",
    "    merge!(cache, Dict(entry => result))\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinValue-function\n",
    "MinValue does the opposite of the MaxValue function. Therefore it looks for the minimum value that black can achieve from a position. Meanwhile white tries to maximize the value of the position. Therefore black will take the minimal value of the maximum value of the next move that can happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`minValue(State::Board, depth::Int64)` is the **non-incremental** implementation of the minValue function. It takes in the current `State` (Type `Board`) and the max-`depth` (Type `Int64`) it should calculate and returns the minimal score it can achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minValue(State::Board, depth::Int64)::Int64\n",
    "    if isterminal(State) || depth == 0\n",
    "      return evaluate_position(State) + depth\n",
    "    end\n",
    "    return minimum([ maxValue(domove(State, ns), depth-1) for ns in moves(State) ])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`minValue(State::Board, score, depth::Int64)` is the **incremental** implementation of the minValue function. It takes in the current `State` (Type `Board`), the current centipawn-`score` of the board and the max-`depth` (Type `Int64`) it should calculate and returns the minimal score it can achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minValue(State::Board, score::Int64, depth::Int64)::Int64\n",
    "    if isterminal(State) \n",
    "        return terminal_evaluation(State) + depth\n",
    "    end\n",
    "    if depth == 0\n",
    "        return score\n",
    "    end\n",
    "    value = Inf\n",
    "    for move in moves(State)\n",
    "        nextEval = evaluate_move(State, move, score)\n",
    "        undoinfo = domove!(State, move)\n",
    "        value = min(maxValue(State, nextEval, depth-1), value)\n",
    "        undomove!(State, undoinfo)\n",
    "    end\n",
    "    return value\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with Memoization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minValue(State::Board, score::Int64, depth::Int64, cache)::Int64\n",
    "    # Memoization\n",
    "    entry = (\"minValue\", deepcopy(State), depth)\n",
    "    if entry in keys(cache)\n",
    "        return cache[entry]\n",
    "    end\n",
    "    if isterminal(State) \n",
    "        result = terminal_evaluation(State) - depth\n",
    "    elseif depth == 0\n",
    "        result = score\n",
    "    else\n",
    "        result = Inf\n",
    "        for move in moves(State)\n",
    "            nextEval = evaluate_move(State, move, score)\n",
    "            undoinfo = domove!(State, move)\n",
    "            result = min(maxValue(State, nextEval, depth-1, cache), result)\n",
    "            undomove!(State, undoinfo)\n",
    "        end\n",
    "    end\n",
    "    # Save in Cache\n",
    "    merge!(cache, Dict(entry => result))\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Memoization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"Memoization.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `invoke` to overwrite the functions defined above. Q: https://discourse.julialang.org/t/overwriting-functions/404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxValue(State::Board, score::Int64, depth::Int64) = invoke(memoize(maxValue(State::Board, score::Int64, depth::Int64), Tuple{Board, Int64, Int64}, State, score, depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minValue(State::Board, score::Int64, depth::Int64) = invoke(memoize(minValue(State::Board, score::Int64, depth::Int64), Tuple{Board, Int64, Int64}, State, score, depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax-function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `minimax` function takes in a `State` (Type `Board`) and the max-`depth` the algorithm should calculate and returns a pair containing the centipawn-value of the best move and the board of the best move."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non-inkremental implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minimax(State::Board, depth::Int64)::Int64\n",
    "    next_moves = moves(State)\n",
    "    if sidetomove(State) == WHITE\n",
    "        bestVal = maxValue(State, depth)\n",
    "        BestMoves = [move for move in next_moves if minValue(domove(State, move), depth-1) == bestVal]\n",
    "    elseif sidetomove(State) == BLACK\n",
    "        bestVal = minValue(State, depth)\n",
    "        BestMoves = [move for move in next_moves if maxValue(domove(State, move), depth-1) == bestVal]\n",
    "    end\n",
    "    BestMove = rand(BestMoves)\n",
    "    return bestVal, BestMove\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### incremental implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minimax(State::Board, score::Int64, depth::Int64, cache=Dict())::Tuple{Int64, Move}\n",
    "    BestMoves = []\n",
    "    bestVal = 0\n",
    "    if sidetomove(State) == WHITE\n",
    "        bestVal = maxValue(State, score, depth, cache)\n",
    "        for move in moves(State)\n",
    "            nextEval = evaluate_move(State, move, score)\n",
    "            undoinfo = domove!(State, move)\n",
    "            if minValue(State, nextEval, depth-1, cache) == bestVal\n",
    "                append!(BestMoves, [move])\n",
    "            end\n",
    "            undomove!(State, undoinfo)\n",
    "        end\n",
    "    elseif sidetomove(State) == BLACK\n",
    "        bestVal = minValue(State, score, depth, cache)\n",
    "        for move in moves(State)\n",
    "            nextEval = evaluate_move(State, move, score)\n",
    "            undoinfo = domove!(State, move)\n",
    "            if maxValue(State, nextEval, depth-1, cache) == bestVal\n",
    "                append!(BestMoves, [move])\n",
    "            end\n",
    "            undomove!(State, undoinfo)\n",
    "        end\n",
    "    end\n",
    "    BestMove = rand(BestMoves)\n",
    "    return bestVal, BestMove\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
