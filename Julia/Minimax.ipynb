{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(read(open(\"style.css\"), String))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "# Pkg.add(\"Chess\")\n",
    "using Chess\n",
    "using Random\n",
    "\n",
    "# Pkg.add(\"NBInclude\")\n",
    "using NBInclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"AdvancedBoard.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gCache = Dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A program to play a game of chess using the Minimax algorithm. The Minimax algorithm calculates all different possibilities of the current position and chooses the best move. It assumes that all players try to play the best possible moves. From whites perspective white chooses the best move of blacks best moves. We have to limit the amout of moves that minimax will go into the future due to the huge amount of possibilities that chess has. Therefore we stop the minimax algorithm at a certain depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimax algorithm can be described using these functions:\n",
    "\n",
    "Note:\n",
    "$finished(s) = isterminal(s) | depth == 0$\n",
    "\n",
    "1. $finished(s) \\longrightarrow minValue(s) = evaluate\\_position(s)$\n",
    "1. $\\neg finished(s) \\longrightarrow minValue(s) = min(\\{maxValue(n) | n \\in nextStates(s)\\})$\n",
    "1. $finished(s) \\longrightarrow maxValue(s) = evaluate\\_position(s)$\n",
    "1. $\\neg finished(s) \\longrightarrow maxValue(s) = min(\\{minValue(n) | n \\in nextStates(s)\\})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax-function non incremental no memoization\n",
    "### MaxValue\n",
    "This function looks for the maximum value that white can achieve from a position. Meanwhile black tries to minimize the value of the position. Therefore white will take the maximal value of the minimum value of the next move that can happen.\n",
    "\n",
    "Note: The depth is subtracted/added to give a better/worse rating to evaluate short mating paths as a petter path. (if there is a Mate in 3 (M3) and M1 Path then choose the M1 Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `maxValue_noIncNoMem` is the **non-incremental** implementation of the maxValue function. \n",
    "\n",
    "Arguments:\n",
    "1. `State::Board` is the current state\n",
    "1. `depth::Int64` is the maximal plys minimax should calculate \n",
    "\n",
    "Returns the maximal score white can achieve with perfect play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function maxValue_noIncNoMem(State::Board, depth::Int64)::Int64\n",
    "    if isterminal(State) || depth == 0\n",
    "        return evaluate_position(State) - depth\n",
    "    end\n",
    "    return maximum([ minValue_noIncNoMem(domove(State, ns), depth-1) for ns in moves(State) ])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinValue does the opposite of the MaxValue function. Therefore it looks for the minimum value that black can achieve from a position. Meanwhile white tries to maximize the value of the position. Therefore black will take the minimal value of the maximum value of the next move that can happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `minValue_noIncNoMem` is the **non-incremental** implementation of the minValue function. \n",
    "\n",
    "Arguments:\n",
    "1. `State::Board` is the current state\n",
    "1. `depth::Int64` is the maximal plys minimax should calculate \n",
    "\n",
    "Returns the minimal score black can achieve with perfect play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minValue_noIncnoMem(State::Board, depth::Int64)::Int64\n",
    "    if isterminal(State) || depth == 0\n",
    "      return evaluate_position(State) + depth\n",
    "    end\n",
    "    return minimum([ maxValue_noIncNoMem(domove(State, ns), depth-1) for ns in moves(State) ])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax incremental but no Memoization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `maxValue_NoMem` is the **incremental** implementation of the maxValue function. \n",
    "\n",
    "Arguments:\n",
    "1. `State::Board` is the current state\n",
    "1. `score::Int64` current evaluation of the board\n",
    "1. `depth::Int64` is the maximal plys minimax should calculate \n",
    "\n",
    "Returns the minimal score white can achieve with perfect play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function maxValue_noMem(State::Board, score::Int64, depth::Int64)::Int64\n",
    "    if isterminal(State) \n",
    "        return terminal_evaluation(State) - depth\n",
    "    end\n",
    "    if depth == 0\n",
    "        return score\n",
    "    end\n",
    "    value = -Inf\n",
    "    for move in moves(State)\n",
    "        nextEval = evaluate_move(State, move, score)\n",
    "        undoinfo = domove!(State, move)\n",
    "        value = max(minValue_noMem(State, nextEval, depth-1), value)\n",
    "        undomove!(State, undoinfo)\n",
    "    end\n",
    "    return value\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `minValue_NoMem` is the **incremental** implementation of the minValue function. \n",
    "\n",
    "Arguments:\n",
    "1. `State::Board` is the current state\n",
    "1. `score::Int64` current evaluation of the board\n",
    "1. `depth::Int64` is the maximal plys minimax should calculate \n",
    "\n",
    "Returns the minimal score black can achieve with perfect play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minValue_noMem(State::Board, score::Int64, depth::Int64)::Int64\n",
    "    if isterminal(State) \n",
    "        return terminal_evaluation(State) + depth\n",
    "    end\n",
    "    if depth == 0\n",
    "        return score\n",
    "    end\n",
    "    value = Inf\n",
    "    for move in moves(State)\n",
    "        nextEval = evaluate_move(State, move, score)\n",
    "        undoinfo = domove!(State, move)\n",
    "        value = min(maxValue_noMem(State, nextEval, depth-1), value)\n",
    "        undomove!(State, undoinfo)\n",
    "    end\n",
    "    return value\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax incremental and with Memoization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `maxValue` is the **incremental** implementation of the maxValue function using a cache. \n",
    "\n",
    "Arguments:\n",
    "1. `State::Board` is the current state\n",
    "1. `depth::Int64` is the maximal plys minimax should calculate\n",
    "1. `cache` is the cache that is used to save the entries\n",
    "\n",
    "Returns the minimal score white can achieve with perfect play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function maxValue(aBoard::AdvBoard, depth::Int64, cache)::Int64\n",
    "    # Memoization\n",
    "    entry = (\"maxValue\", aBoard.hash, depth)\n",
    "    if entry in keys(cache)\n",
    "        return cache[entry]\n",
    "    end\n",
    "    if isterminal(aBoard.state)\n",
    "        result = terminal_evaluation(aBoard) - depth\n",
    "    elseif depth == 0\n",
    "        result = aBoard.score\n",
    "    else\n",
    "        result = -200000\n",
    "        for move in moves(aBoard.state)\n",
    "            undoinfo = domoveAdv!(aBoard, move)\n",
    "            result = max(minValue(aBoard, depth-1, cache), result)\n",
    "            undomoveAdv!(aBoard, undoinfo)\n",
    "        end\n",
    "    end\n",
    "    # Save in Cache\n",
    "    merge!(cache, Dict(entry => result))\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `minValue` is the **incremental** implementation of the minValue function that uses a cache. \n",
    "\n",
    "Arguments:\n",
    "1. `State::Board` is the current state\n",
    "1. `depth::Int64` is the maximal plys minimax should calculate \n",
    "1. `cache` is the cache that is used to save the entries\n",
    "\n",
    "Returns the minimal score black can achieve with perfect play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minValue(aBoard::AdvBoard, depth::Int64, cache)::Int64\n",
    "    # Memoization\n",
    "    entry = (\"minValue\", aBoard.hash, depth)\n",
    "    if entry in keys(cache)\n",
    "        return cache[entry]\n",
    "    end\n",
    "    if isterminal(aBoard.state)\n",
    "        result = terminal_evaluation(aBoard) + depth\n",
    "    elseif depth == 0\n",
    "        result = aBoard.score\n",
    "    else\n",
    "        result = 200000\n",
    "        for move in moves(aBoard.state)\n",
    "            undoinfo = domoveAdv!(aBoard, move)\n",
    "            result = min(maxValue(aBoard, depth-1, cache), result)\n",
    "            undomoveAdv!(aBoard, undoinfo)\n",
    "        end\n",
    "    end\n",
    "    # Save in Cache\n",
    "    merge!(cache, Dict(entry => result))\n",
    "    return result\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax-function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non-incremental implementation \n",
    "\n",
    "`minimax` is a function that implements the minimax algorithm to determine the best move for the current player at the current game state. This is the non-incremental implementation and does not have AdvBoard implemented into it. \n",
    "\n",
    "Arguments:\n",
    "1. `State::Board` An advanced chess board in the current state.\n",
    "1. `score::Int64` current evaluation of the board\n",
    "1. `depth::Int64:` The maximum depth to search.\n",
    "\n",
    "Returns:\n",
    "1. `Tuple{Int64, Move}`: a tuple containing the best score and the corresponding best move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minimax_noMem(State::Board, score::Int64, depth::Int64)::Tuple{Int64, Move}\n",
    "    next_moves = moves(State)\n",
    "    if sidetomove(State) == WHITE\n",
    "        bestVal = maxValue_noMem(State, score, depth)\n",
    "        println(bestVal)\n",
    "        BestMoves = [move for move in next_moves \n",
    "                     if minValue_noMem(domove(State, move), evaluate_move(State, move, score), depth-1) == bestVal]\n",
    "        for move in next_moves\n",
    "            println(minValue_noMem(domove(State, move), score, depth-1))\n",
    "        end\n",
    "    elseif sidetomove(State) == BLACK\n",
    "        bestVal = minValue_noMem(State, score, depth)\n",
    "        BestMoves = [move for move in next_moves \n",
    "                     if maxValue_noMem(domove(State, move), evaluate_move(State, move, score), depth-1) == bestVal]\n",
    "    end\n",
    "    println(BestMoves)\n",
    "    BestMove = rand(BestMoves)\n",
    "    return bestVal, BestMove\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### incremental implementation \n",
    "\n",
    "`minimax` is a function that implements the minimax algorithm to determine the best move for the current player at the current game state.\n",
    "\n",
    "Arguments:\n",
    "1. `aBoard::AdvBoard:` An advanced chess board in the current state.\n",
    "1. `depth::Int64:` The maximum depth to search.\n",
    "1. `cache::Dict{}`: a dictionary that stores previously calculated values\n",
    "\n",
    "Returns:\n",
    "1. `Tuple{Int64, Move}`: a tuple containing the best score and the corresponding best move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minimax(aBoard::AdvBoard, depth::Int64, cache=Dict())::Tuple{Int64, Move}\n",
    "    BestMoves = []\n",
    "    side = sidetomove(aBoard.state)\n",
    "    bestVal = (side == WHITE) ? -200000 : 200000\n",
    "    if side == WHITE\n",
    "        bestVal = maxValue(aBoard, depth, cache)\n",
    "        for move in moves(aBoard.state)\n",
    "            undoinfo = domoveAdv!(aBoard, move)\n",
    "            if minValue(aBoard, depth-1, cache) == bestVal\n",
    "                append!(BestMoves, [move])\n",
    "            end\n",
    "            undomoveAdv!(aBoard, undoinfo)\n",
    "        end\n",
    "    elseif side == BLACK\n",
    "        bestVal = minValue(aBoard, depth, cache)\n",
    "        for move in moves(aBoard.state)\n",
    "            undoinfo = domoveAdv!(aBoard, move)\n",
    "            if maxValue(aBoard, depth-1, cache) == bestVal\n",
    "                append!(BestMoves, [move])\n",
    "            end\n",
    "            undomoveAdv!(aBoard, undoinfo)\n",
    "        end\n",
    "    end\n",
    "    BestMove = rand(BestMoves)\n",
    "    return bestVal, BestMove\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
