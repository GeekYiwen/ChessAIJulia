{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(read(open(\"style.css\"), String))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha-Beta Pruning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements an AI which calculates the best move for a chess game using alpha-beta-Pruning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "# Pkg.add(\"Chess\")\n",
    "using Chess\n",
    "using Random\n",
    "\n",
    "# Pkg.add(\"NBInclude\")\n",
    "using NBInclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"EvaluatePosition.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"Memoization.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlphaBetaMax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `alphaBetaMax_noMem` function takes in 3 arguments and 2 optional arguments.\n",
    "1. `State` is a chess `state` of type `Board`\n",
    "1. `score` is the static centipawn evaluation of the `state`\n",
    "1. `depth` is the number of halfmoves the engine should analyze before terminating \n",
    "1. `alpha` is optional and is default to -Infinity. Alpha is a minimal value that has been calculated during the recursive process\n",
    "1. `beta`  is optional and is default to Infinity . Beta is a maximal value that has been calculated during the recursive process\n",
    "\n",
    "The function returns the maximal centipawn evaluation of the current position for the player playing white where both players have played the optimal moves according to the algorithm and terminating after the given depth. This function does not use Memoization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function alphaBetaMax_noMem(State::Board, score::Int64, depth::Int64, alpha::Int64=-200000, beta::Int64=200000)::Int64\n",
    "    if isterminal(State)\n",
    "        return terminal_evaluation(State) - depth\n",
    "    end\n",
    "    if depth == 0\n",
    "        return score\n",
    "    end\n",
    "    for move in moves(State)\n",
    "        nextEval = evaluate_move(State, move, score)\n",
    "        undoinfo = domove!(State, move)\n",
    "        value = alphaBetaMin_noMem(State, nextEval, depth - 1, alpha, beta)\n",
    "        undomove!(State, undoinfo)\n",
    "        if value >= beta\n",
    "            return value\n",
    "        end\n",
    "        alpha = max(alpha, value)\n",
    "    end\n",
    "    return alpha\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlphaBetaMin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `alphaBetaMin_noMem` function takes in 3 arguments and 2 optional arguments.\n",
    "1. `State` is a chess `state` of type `Board`\n",
    "1. `score` is the static centipawn evaluation of the `state`\n",
    "1. `depth` is the number of halfmoves the engine should analyze before terminating \n",
    "1. `alpha` is optional and is default to -Infinity. Alpha is a minimal value that has been calculated during the recursive process\n",
    "1. `beta`  is optional and is default to Infinity . Beta is a maximal value that has been calculated during the recursive process\n",
    "\n",
    "The function returns the minimal centipawn evaluation of the current position for the player playing black where both players have played the optimal moves according to the algorithm and terminating after the given depth. This function does not use Memoization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function alphaBetaMin_noMem(State::Board, score::Int64, depth::Int64, alpha::Int64=-200000, beta::Int64=200000)::Int64\n",
    "    if isterminal(State)\n",
    "        return terminal_evaluation(State) + depth\n",
    "    end\n",
    "    if depth == 0\n",
    "        return score\n",
    "    end\n",
    "    for move in moves(State)\n",
    "        nextEval = evaluate_move(State, move, score)\n",
    "        undoinfo = domove!(State, move)\n",
    "        value = alphaBetaMax_noMem(State, nextEval, depth - 1, alpha, beta)\n",
    "        undomove!(State, undoinfo)\n",
    "        if value <= alpha\n",
    "            return value\n",
    "        end\n",
    "        beta = min(beta, value)\n",
    "    end\n",
    "    return beta\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha-Beta-Pruning function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `alphaBetaPruning_noMem` function takes in 3 arguments\n",
    "1. `State` is the current state of type `Board`\n",
    "1. `score` is the static centipawn evaluation of the static position\n",
    "1. `depth` is the number of halfmoves the engine should analyze before terminating\n",
    "\n",
    "The function returns the best value and the best move the moving player can play in the current position. It calls the alpha-beta-pruning algorithm. If multiple moves are found which result in the best evaluation a random move will be chosen. This function does not use Memoization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function alphaBetaPruning_noMem(State::Board, score::Int64, depth::Int64)::Tuple{Int64, Move}\n",
    "    next_moves = moves(State)\n",
    "    BestMoves = []\n",
    "    if sidetomove(State) == WHITE\n",
    "        bestVal = alphaBetaMax_noMem(State, Int(score), Int(depth))\n",
    "        for move in next_moves \n",
    "            nextEval = evaluate_move(State, move, score)\n",
    "            undoinfo = domove!(State, move) \n",
    "            if alphaBetaMin_noMem(State, nextEval, depth - 1) == bestVal\n",
    "                append!(BestMoves, [move])\n",
    "            end\n",
    "            undomove!(State, undoinfo)\n",
    "        end\n",
    "    elseif sidetomove(State) == BLACK\n",
    "        bestVal = alphaBetaMin_noMem(State, score, depth)\n",
    "        for move in next_moves \n",
    "            nextEval = evaluate_move(State, move, score)\n",
    "            undoinfo = domove!(State, move)\n",
    "            if alphaBetaMax_noMem(State, nextEval, depth - 1) == bestVal\n",
    "                append!(BestMoves, [move])\n",
    "            end\n",
    "            undomove!(State, undoinfo)\n",
    "        end\n",
    "    end\n",
    "    BestMove = rand(BestMoves)\n",
    "    return bestVal, BestMove\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha-beta-Pruning with Memoization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"Memoization.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlphaBetaMax function with Memoization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `alphaBetaMax` function takes in 4 arguments and 2 optional arguments.\n",
    "1. `State` is a chess `state` of type `Board`\n",
    "1. `score` is the static centipawn evaluation of the `state`\n",
    "1. `depth` is the number of halfmoves the engine should analyze before terminating \n",
    "1. `cache` is a dictionary which stores the calculated values\n",
    "1. `alpha` is optional and is default to -Infinity. Alpha is a minimal value that has been calculated during the recursive process\n",
    "1. `beta`  is optional and is default to Infinity . Beta is a maximal value that has been calculated during the recursive process\n",
    "\n",
    "The function returns the maximal centipawn evaluation of the current position for the player playing white where both players have played the optimal moves according to the algorithm and terminating after the given depth. This function does use Memoization meaning it saves and uses calculated values stored the `Cache`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function alphaBetaMax(State::Board, score::Int64, hash::UInt64, depth::Int64, \n",
    "                      cache::Dict{UInt64, Tuple{String, Int64, Int64}}, alpha::Int64=-200000, beta::Int64=200000)::Int64\n",
    "    if isterminal(State)\n",
    "        return terminal_evaluation(State) - depth\n",
    "    end\n",
    "    if depth == 0\n",
    "        return score\n",
    "    end\n",
    "    for move in moves(State)\n",
    "        nextEval, nextHash = updateBoardData(State, score, hash, move)\n",
    "        undoinfo = domove!(State, move)\n",
    "        value = evaluate(State, alphaBetaMin, nextEval, nextHash, depth - 1, cache, alpha, beta)\n",
    "        undomove!(State, undoinfo)\n",
    "        if value >= beta\n",
    "            return value\n",
    "        end\n",
    "        alpha = max(alpha, value)\n",
    "    end\n",
    "    return alpha\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlphaBetaMin function with memoization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Alpha-Beta-Min function takes in 4 arguments and 2 optional arguments.\n",
    "1. `State` is a chess `state` of type `Board`\n",
    "1. `score` is the static centipawn evaluation of the `state`\n",
    "1. `depth` is the number of halfmoves the engine should analyze before terminating \n",
    "1. `cache` is a dictionary which stores the calculated values\n",
    "1. `alpha` is optional and is default to -Infinity. Alpha is a minimal value that has been calculated during the recursive process\n",
    "1. `beta`  is optional and is default to Infinity . Beta is a maximal value that has been calculated during the recursive process\n",
    "\n",
    "The function returns the minimal centipawn evaluation of the current position for the player playing black where both players have played the optimal moves according to the algorithm and terminating after the given depth. This function does use Memoization meaning it saves and uses calculated values stored the `Cache`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function alphaBetaMin(State::Board, score::Int64, hash::UInt64, depth::Int64, \n",
    "                      cache::Dict{UInt64, Tuple{String, Int64, Int64}}, alpha::Int64=-200000, beta::Int64=200000)::Int64\n",
    "    if isterminal(State)\n",
    "        return terminal_evaluation(State) + depth\n",
    "    end\n",
    "    if depth == 0\n",
    "        return score\n",
    "    end\n",
    "    for move in moves(State)\n",
    "        nextEval, nextHash = updateBoardData(State, score, hash, move)\n",
    "        undoinfo = domove!(State, move)\n",
    "        value = evaluate(State, alphaBetaMax, nextEval, nextHash, depth - 1, cache ,alpha, beta)\n",
    "        undomove!(State, undoinfo)\n",
    "        if value <= alpha\n",
    "            return value\n",
    "        end\n",
    "        beta = min(beta, value)\n",
    "    end\n",
    "    return beta\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `alphaBetaPruning` function takes in 3 arguments and 1 optional argument.\n",
    "1. `State` is the current state of type `Board`\n",
    "1. `score` is the static centipawn evaluation of the static position\n",
    "1. `depth` is the number of halfmoves the engine should analyze before terminating\n",
    "1. `cache` is optional and is default empty dictionary. Cache is a dictionary which stores the calculated values\n",
    "\n",
    "The function returns the best value and the best move the moving player can play in the current position. It calls the alpha-beta-pruning algorithm. If multiple moves are found which result in the best evaluation a random move will be chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function alphaBetaPruning(State::Board, score::Int64, hash::UInt64, depth::Int64,\n",
    "                          cache::Dict{UInt64, Tuple{String, Int64, Int64}} = initCache())::Tuple{Int64, Move}\n",
    "    next_moves = moves(State)\n",
    "    BestMoves = []\n",
    "    if sidetomove(State) == WHITE\n",
    "        bestVal = evaluate(State, alphaBetaMax, score, hash, depth, cache)\n",
    "        for move in next_moves\n",
    "            nextEval, nextHash = updateBoardData(State, score, hash, move)\n",
    "            undoinfo = domove!(State, move)\n",
    "            if evaluate(State, alphaBetaMin, nextEval, nextHash, depth-1, cache) == bestVal\n",
    "                append!(BestMoves, [move])\n",
    "            end\n",
    "            undomove!(State, undoinfo)\n",
    "        end\n",
    "    elseif sidetomove(State) == BLACK\n",
    "        bestVal = evaluate(State, alphaBetaMin, score, hash, depth, cache)\n",
    "        for move in next_moves \n",
    "            nextEval, nextHash = updateBoardData(State, score, hash, move)\n",
    "            undoinfo = domove!(State, move)\n",
    "            if evaluate(State, alphaBetaMax, nextEval, nextHash, depth-1, cache) == bestVal\n",
    "                append!(BestMoves, [move])\n",
    "            end\n",
    "            undomove!(State, undoinfo)\n",
    "        end\n",
    "    end\n",
    "    BestMove = rand(BestMoves)\n",
    "    return bestVal, BestMove\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
