{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(read(open(\"style.css\"), String))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiescence Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiescence Search is a search algorithm designed to avoid the horizon effect in the game of chess. It is called when the search function (e.g. Minimax, alpha-beta-pruning,...) have reached their maximum depth. Quiescence Search will then further search through the game tree until it hits a quiet position. Then and only then it will use the heuristic function to estimate the position. It is important to not stop searching when hitting the end of the depth as this last move can conclude into very good moves for the opposing side. As an example the last move searched by the algorithm is a queen capturing a pawn. The evaluation function therefore will return a score of +100 centipawns as it just took this pawn. Notice that the search algorithm will not see that this pawn was protected resulting in the queen being captured in the move after. This issue is called the **horizon effect**.\n",
    "\n",
    "Quiescence Search will therefore keep calculate all tactical moves and stop when it hits a quiet position. As only the tactical moves will be evaluated, this evaluation will not be taking as much performance as a regular search. Additionally Pruning will result in about 50-90% of paths pruned. (https://www.chessprogramming.org/Quiescence_Search)\n",
    "\n",
    "There are many different approaches on implementing Quiescence Search. The definition of a quiet position also varies. Therefore we define a quiet position as follows:\n",
    "\n",
    "A position is quiet iff: `there are no captures (en passant included)` ∨ `there are no available checks` ∨ `there are no promotions` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "# Pkg.add(\"Chess\")\n",
    "using Chess\n",
    "using NBInclude\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Chess Programming Wiki \"Quiescence Search\"](https://www.chessprogramming.org/Quiescence_Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"Memoization.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: hasCaptureMoves\n",
    "This function takes in a chess game state and returns a boolean indicating whether there are any capture moves available for the opponent.\n",
    "\n",
    "Arguments:\n",
    "1. `State::Board` A chess board in the current state.\n",
    "\n",
    "Returns:\n",
    "1. `true` if there are any capture moves available for the opponent, `false` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function hasCaptureMoves(State::Board)\n",
    "    allPiecesSq = pieces(State, coloropp(sidetomove(State)))\n",
    "    return any(isattacked(State, square, coloropp(sidetomove(State))) for square in allPiecesSq)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: isTacticalMove\n",
    "The function `isTacticalMove` checks whether the move done on a state is a tactical move. \n",
    "\n",
    "A move is a tactical move if is one of the following is true:\n",
    "1. The move is capturing a piece\n",
    "1. The move is promoting a pawn\n",
    "1. The move is an en passant capture\n",
    "1. The move checks the opposing king\n",
    "\n",
    "Arguments:\n",
    "\n",
    "1. `State::Board` The current board\n",
    "1. `move::Move`   The move on the `State` that should be checked for tactical moves\n",
    "\n",
    "Returns:\n",
    "\n",
    "1. `true` if the move is a tactical move, otherwise false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function isTacticalMove(State::Board, move::Move)\n",
    "    if pieceon(State, to(move)) != EMPTY || ispromotion(move) || epsquare(State) == to(move)\n",
    "        return true\n",
    "    end\n",
    "    undoinfo = domove!(State, move)\n",
    "    isNextMoveCheck = ischeck(State)\n",
    "    undomove!(State, undoinfo)\n",
    "    return isNextMoveCheck\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function currently not used. TODO: Check whether this function is useful? bad performance\n",
    "function isQuiet(State)\n",
    "    return any(isTacticalMove(State, move) for move in moves(State))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Quiescence Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First version: quiescenceNoPrune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `quiescenceNoPrune` uses the quiescence algorithm to determine the best score. It only stops searching if the position is quiet and only searches through positions which have tactical moves. This function does not contain any pruning attempts and therefore has a very long runtime.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "1. `State::Board` The current board\n",
    "1. `score::Int64` The score of the current board\n",
    "1. `hash::UInt64` The hash of the current board\n",
    "\n",
    "Returns:\n",
    "\n",
    "1. `bestScore::Int64` The best score that can be achieved for the current State if both sides play optimally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## not used, because of bad performance\n",
    "function quiesceNoPrune(State, score, hash)\n",
    "    bestscore = score\n",
    "    for move in moves(State)\n",
    "        if isTacticalMove(State, move)\n",
    "            nextScore, nextHash = updateBoardData(State, score, hash, move)\n",
    "            # nextBoard = domove(State, move)\n",
    "            undoinfo = domove!(State, move)\n",
    "            # value = -evaluate(State, quiesce, nextScore, nextHash, depth-1, -beta, -alpha)\n",
    "            value = quiesceNoPrune(State, nextScore, nextHash)\n",
    "            undomove!(State, undoinfo)\n",
    "            bestscore = sidetomove(State) == WHITE ? max(bestscore, value) : min(bestscore, value)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return bestscore\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `quiescence` uses the quiescence algorithm to determine the best score. It only stops searching if the position is quiet and only searches through positions which have tactical moves. This function is often implemented in literature but implements a version fitting the `Negamax` function. As this project uses `Alpha-Beta-Pruning` and therefore has a different evaluation method this function cannot be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NegaMax version of Quiescence: not used\n",
    "function quiesce(State, score, hash, depth, alpha, beta)\n",
    "    display(State)\n",
    "    println(\"$(score), $(depth), $(alpha), $(beta)\")\n",
    "    value = score\n",
    "    if value >= beta\n",
    "        println(\"Pruned 1\")\n",
    "        return beta\n",
    "    end\n",
    "    if value > alpha\n",
    "        alpha = value\n",
    "    end\n",
    "    for move in moves(State)\n",
    "        if isTacticalMove(State, move)\n",
    "            nextScore, nextHash = updateBoardData(State, score, hash, move)\n",
    "            \n",
    "            undoinfo = domove!(State, move)\n",
    "            \n",
    "            # value = -evaluate(State, quiesce, nextScore, nextHash, depth-1, -beta, -alpha)\n",
    "            value = -quiesce(State, nextScore, nextHash, depth-1, -beta, -alpha)\n",
    "            \n",
    "            println(value)\n",
    "            undomove!(State, undoinfo)\n",
    "            \n",
    "            if value >= beta\n",
    "                return beta\n",
    "            end\n",
    "            if value > alpha\n",
    "                alpha = value\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return alpha\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiescence Min and Max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `quiescenceMax` uses the quiescence algorithm to determine the best score (meaning maximizing the score) for positions where white moves. It only stops searching if the position is quiet and only searches through positions which have tactical moves.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "1. `State::Board` The current board\n",
    "1. `score::Int64` The score of the current board\n",
    "1. `hash::UInt64` The hash of the current board\n",
    "1. `depth::Int64` The depth of the search (initially always set to 0 and decremented by each step)\n",
    "1. `alpha::Int64` The lower boundary of the score for this search\n",
    "1. `beta::Int64`  The upper boundary of the score for this search\n",
    "\n",
    "Returns:\n",
    "\n",
    "1. `score::Int64` The best score that can be achieved for the current State if both sides play optimally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function quiesceMax(aBoard::AdvBoard, depth::Int64, \n",
    "                    cache::Dict{UInt64, Tuple{String, Int64, Int64}}, alpha::Int64, beta::Int64)::Int64\n",
    "    value::Int64 = aBoard.score\n",
    "    value >= beta && return beta\n",
    "    alpha = max(alpha, value)\n",
    "    \n",
    "    for move in moves(aBoard.state)\n",
    "        isTacticalMove(aBoard.state, move) || continue\n",
    "        undoinfo::Tuple{Int64, UInt64, UndoInfo} = domoveAdv!(aBoard, move)\n",
    "        value = evaluate(aBoard, quiesceMin, depth-1, cache, alpha, beta)\n",
    "        # value = quiesceMin(State, nextScore, nextHash, depth-1, alpha, beta)\n",
    "        undomoveAdv!(aBoard, undoinfo)\n",
    "        value >= beta && return beta\n",
    "        alpha = max(alpha, value) \n",
    "    end\n",
    "    return alpha\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `quiescenceMin` uses the quiescence algorithm to determine the best score (meaning minimizing the score) for positions where black moves. It only stops searching if the position is quiet and only searches through positions which have tactical moves.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "1. `State::Board` The current board\n",
    "1. `score::Int64` The score of the current board\n",
    "1. `hash::UInt64` The hash of the current board\n",
    "1. `depth::Int64` The depth of the search (initially always set to 0 and decremented by each step)\n",
    "1. `alpha::Int64` The lower boundary of the score for this search\n",
    "1. `beta::Int64`  The upper boundary of the score for this search\n",
    "\n",
    "Returns:\n",
    "\n",
    "1. `score::Int64` The best score that can be achieved for the current State if both sides play optimally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function quiesceMin(aBoard::AdvBoard, depth::Int64, \n",
    "                    cache::Dict{UInt64, Tuple{String, Int64, Int64}}, alpha::Int64, beta::Int64)::Int64\n",
    "    value = aBoard.score\n",
    "    value <= alpha && return alpha\n",
    "    beta = min(value, beta)\n",
    "    \n",
    "    for move in moves(aBoard.state)\n",
    "        isTacticalMove(aBoard.state, move) || continue\n",
    "        undoinfo::Tuple{Int64, UInt64, UndoInfo} = domoveAdv!(aBoard, move)\n",
    "        value = evaluate(aBoard, quiesceMax, depth-1, cache, alpha, beta)\n",
    "        # value = quiesceMax(State, nextScore, nextHash, depth-1, alpha, beta)\n",
    "        undomoveAdv!(aBoard, undoinfo)\n",
    "        value <= alpha && return alpha\n",
    "        beta = min(value, beta)\n",
    "    end\n",
    "    return beta\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiescence Search with see() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `quiesceSee` uses the `see()` function from `Chess.jl` to determine an estimate whether any pieces may be captured in the near future. As the see function returns a value that represents the difference in value in material point. Therefore this value is multiplied by 100 as this roughly delivers the centipawn value.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "1. `State::Board` The current board\n",
    "1. `score::Int64` The score of the current board\n",
    "1. `alpha::Int64` The lower boundary of the score for this search\n",
    "1. `beta::Int64`  The upper boundary of the score for this search\n",
    "\n",
    "Returns:\n",
    "\n",
    "1. `score::Int64` The best score that can be achieved for the current State if both sides play optimally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function quiesceSee(State::Board, score::Int64, alpha::Int64, beta::Int64)\n",
    "    if sidetomove(State) == WHITE\n",
    "        bestEstimate::Int64 = -200000\n",
    "        for move in moves(State)\n",
    "            bestEstimate = max(bestEstimate, see(State, move))\n",
    "        end\n",
    "    else \n",
    "        bestEstimate = 200000\n",
    "        for move in moves(State)\n",
    "            bestEstimate = min(bestEstimate, see(State, move))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return score + bestEstimate * 100\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategic Quiescence Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function evalPlus(State)\n",
    "    if isCheck(State)\n",
    "        return Inf\n",
    "    end\n",
    "    if hasCaptureMoves(State) && ispromotion(State)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function strategicQS(State, score, hash, alpha, beta)\n",
    "    value = score\n",
    "    if value >= beta\n",
    "        return beta\n",
    "    end\n",
    "    if value > alpha\n",
    "        alpha = value\n",
    "    end\n",
    "    \n",
    "    for move in moves(State)\n",
    "        nextScore, nextHash = updateBoardData(State, score, hash, move)\n",
    "        undoinfo = domove!(State, move)\n",
    "        evalPlusValue = evalPlus(State)\n",
    "        if evalPlusValue > alpha\n",
    "            actVal = -strategicQS(State, nextScore, nextHash, -beta, -alpha)\n",
    "            if actVal > value\n",
    "                value = actVal\n",
    "                if value >= beta\n",
    "                    return beta\n",
    "                end\n",
    "                if value > alpha\n",
    "                    alpha = value\n",
    "                end\n",
    "            end\n",
    "        elseif evalPlusValue > value\n",
    "            value = evalPlusValue\n",
    "        end\n",
    "        undomove!(State, move)\n",
    "    end\n",
    "    return value\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
